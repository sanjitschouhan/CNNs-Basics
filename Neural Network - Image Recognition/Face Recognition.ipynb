{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition (Research Project)\n",
    "\n",
    "Recognising Faces of famous Celebrities\n",
    "\n",
    "### Data Used\n",
    "VGG Face data of about 3000+ Celebrities with 1000 images each\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "if False:\n",
    "    ! conda install scipy -y -q\n",
    "    ! conda install matplotlib -y -q\n",
    "    ! conda install pillow -y -q\n",
    "    ! conda install PIL -y -q\n",
    "    ! conda install scikit-image -y -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import scipy\n",
    "from scipy import ndimage, misc\n",
    "from skimage.transform import resize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Class for a dataset\n",
    "class DataSet(object):\n",
    "    \"\"\"Dataset class object.\"\"\"\n",
    "\n",
    "    def __init__(self, images, labels, reshape=False):\n",
    "        \"\"\"Initialize the class.\"\"\"\n",
    "        if reshape:\n",
    "            assert images.shape[3] == 1\n",
    "            images = images.reshape(images.shape[0],\n",
    "                images.shape[1] * images.shape[2])\n",
    "\n",
    "        self._images = images\n",
    "        self._num_examples = images.shape[0]\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            print \"Epochs Completed: \",self._epochs_completed\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "\n",
    "        return self._images[start:end], self._labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimentions to be used in model\n",
    "height, width = 256/2, 256/2\n",
    "n_classes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to resize images\n",
    "def resize_image(img):\n",
    "    global height, width\n",
    "    r_img = resize(img,(height,width,3),mode='constant')\n",
    "    return r_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_cmd_line(output):\n",
    "    \"\"\"Replace the last command line output with the given output.\"\"\"\n",
    "    sys.stdout.write(output)\n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from folders\n",
    "def LoadData(path, validatation_data_percentage, test_data_percentage):\n",
    "    assert (validatation_data_percentage>0 and validatation_data_percentage<=50), \"Invalid Validation Percentage(1-50)\"\n",
    "    assert (test_data_percentage>0 and test_data_percentage<=50), \"Invalid Test Percentage(1-50)\"\n",
    "    assert (validatation_data_percentage+test_data_percentage<100), \"Invalid Percentages(validation+test<100)\"\n",
    "\n",
    "    classes = os.listdir(path)\n",
    "    \n",
    "    global n_classes\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    prompt=\"Loading Data: \"\n",
    "    \n",
    "    n = 0\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in classes:\n",
    "        for img_file in os.listdir(path + label)[:50]:\n",
    "            img = ndimage.imread(path+label+\"/\"+img_file,mode='RGB')\n",
    "            images.append(resize_image(img))\n",
    "            replace_cmd_line(prompt+label+' '+img_file)\n",
    "            labels.append(n)\n",
    "        n+=1\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    labels = np.identity(len(classes))[labels]\n",
    "    \n",
    "    print prompt+\"Done\"+\" \"*30\n",
    "    \n",
    "    total_data_size = len(labels)\n",
    "    print \"Shuffling Data...\",\n",
    "    perm = np.arange(total_data_size)\n",
    "    np.random.shuffle(perm)\n",
    "    images = images[perm]\n",
    "    labels = labels[perm]\n",
    "    print \"Done\"\n",
    "    \n",
    "    print \"Splitting Data...\",\n",
    "    validation_data_size = total_data_size * validatation_data_percentage / 100\n",
    "    test_data_size = total_data_size * test_data_percentage / 100\n",
    "    \n",
    "    test_data_images = images[:test_data_size]\n",
    "    test_data_labels = labels[:test_data_size]\n",
    "    \n",
    "    validation_data_images = images[test_data_size:test_data_size+validation_data_size]\n",
    "    validation_data_labels = labels[test_data_size:test_data_size+validation_data_size]\n",
    "    \n",
    "    train_data_images = images[test_data_size+validation_data_size:]\n",
    "    train_data_labels = labels[test_data_size+validation_data_size:]\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    return DataSet(train_data_images, train_data_labels), DataSet(validation_data_images, validation_data_labels), DataSet(test_data_images, test_data_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data: Aamir_Khan 00000121.png\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0.\n",
      "Use ``matplotlib.pyplot.imread`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data: Done                              \n",
      "Shuffling Data... Done\n",
      "Splitting Data... Done\n"
     ]
    }
   ],
   "source": [
    "trainset, validationset, testset = LoadData(\"../data/faces_images/\", 20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tImages\t\t\tLabels\n",
      "Training:\t(213, 128, 128, 3) \t(213, 10)\n",
      "Validation:\t(71, 128, 128, 3) \t(71, 10)\n",
      "Testing:\t(71, 128, 128, 3) \t(71, 10)\n"
     ]
    }
   ],
   "source": [
    "print '\\t\\tImages\\t\\t\\tLabels'\n",
    "print 'Training:\\t', trainset.images.shape,'\\t', trainset.labels.shape\n",
    "print 'Validation:\\t', validationset.images.shape,'\\t', validationset.labels.shape\n",
    "print 'Testing:\\t', testset.images.shape,'\\t', testset.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: 16384\n",
      "Number of Classes: 10\n",
      "Batch Size: 32\n",
      "No of Steps: 1000\n",
      "Kernel Size: [3, 3]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "steps = 1000\n",
    "\n",
    "n_input = height * width\n",
    "\n",
    "kernel_size = [3,3]\n",
    "input_channels = 3\n",
    "output_channels = 64\n",
    "\n",
    "print 'Input Size:',n_input\n",
    "print 'Number of Classes:', n_classes\n",
    "print 'Batch Size:', batch_size\n",
    "print 'No of Steps:', steps\n",
    "print 'Kernel Size:', kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial,name=\"weight\")\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial, name=\"bias\")\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,3,3,1], strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.GeneratorContextManager at 0x7f79106f6ad0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, height,width,3], name=\"input_features\")\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name=\"labels\")\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "# layer 1 ?x128x128x3 => ?x64x64x64\n",
    "W_conv1 = weight_variable([3,3,3,64])\n",
    "b_conv1 = bias_variable([64])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1, name=\"h_conv1\")\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# layer 2 ?x64x64x64 => ?x32x32x128\n",
    "W_conv2 = weight_variable([3,3,64,128])\n",
    "b_conv2 = bias_variable([128])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, name=\"h_conv2\")\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# layer 3 ?x32x32x128 => ?x16x16x256\n",
    "W_conv3 = weight_variable([3,3,128,256])\n",
    "b_conv3 = bias_variable([256])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3, name=\"h_conv3\")\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "# layer 4 ?x16x16x256 => ?x8x8x512\n",
    "W_conv4 = weight_variable([3,3,256,512])\n",
    "b_conv4 = bias_variable([512])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4, name=\"h_conv4\")\n",
    "h_pool4 = max_pool_2x2(h_conv4)\n",
    "\n",
    "# fully connected layer 1  ?x8x8x512 => ?x1024\n",
    "W_fc1 = weight_variable([8*8*512,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool4_flat = tf.reshape(h_pool4, [-1, 8*8*512], name=\"flattened_pool_layer\")\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat,W_fc1) + b_fc1, name=\"h_fc1\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name=\"h_fc1_drop\")\n",
    "\n",
    "# fully connected layer 2   ?x1024 => ?xn_classes\n",
    "W_fc2 = weight_variable([1024,n_classes])\n",
    "b_fc2 = bias_variable([n_classes])\n",
    "y_conv = tf.matmul(h_fc1_drop ,W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv), name=\"cross_entropy\")\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.01,name=\"optimizer\").minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1), name=\"correct_prediction\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32), name=\"accuracy\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(\"log\", y_conv.graph);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, \"saved models/model\"+str(n_classes)+\".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.140845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/inspect.py\", line 1051, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/inspect.py\", line 1011, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/inspect.py\", line 453, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/inspect.py\", line 499, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/posixpath.py\", line 376, in realpath\n",
      "    return abspath(path)\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/posixpath.py\", line 366, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/posixpath.py\", line 341, in normpath\n",
      "    comps = path.split('/')\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[1;32m   1824\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1826\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1412\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1320\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m             )\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sanjit/miniconda2/envs/tensorflow/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "graphx = []\n",
    "graphy = []\n",
    "for i in range(steps+1):\n",
    "    if i%10==0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: validationset.images, y: validationset.labels, keep_prob: 1.0}, session=sess)\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        graphx.append(i)\n",
    "        graphy.append(train_accuracy*100)\n",
    "    batch = trainset.next_batch(batch_size)\n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1], keep_prob:0.5}, session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.084507524967194]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7903101590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print graphy\n",
    "plt.plot(graphx,graphy)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.0422535\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy.eval(feed_dict={x: testset.images, y: testset.labels, keep_prob: 1.0}, session=sess)\n",
    "print 'test accuracy %g' % test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"saved models/model\"+str(n_classes)+\".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
