{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "\n",
    "import scipy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.legacy import nn\n",
    "from scipy import ndimage, misc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "    \"\"\"Dataset class object.\"\"\"\n",
    "\n",
    "    def __init__(self, images, labels, reshape=False):\n",
    "        \"\"\"Initialize the class.\"\"\"\n",
    "        if reshape:\n",
    "            assert images.shape[3] == 1\n",
    "            images = images.reshape(images.shape[0],\n",
    "                images.shape[1] * images.shape[2])\n",
    "\n",
    "        self._images = images\n",
    "        self._num_examples = images.shape[0]\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            print \"Epochs Completed: \",self._epochs_completed\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm)\n",
    "            self._images = self._images[perm]\n",
    "            self._labels = self._labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "\n",
    "        return self._images[start:end], self._labels[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height, width = 256/2, 256/2\n",
    "n_classes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resize_image(img):\n",
    "    global height, width\n",
    "    return misc.imresize(img,(height,width))\n",
    "\n",
    "def replace_cmd_line(output):\n",
    "    \"\"\"Replace the last command line output with the given output.\"\"\"\n",
    "    sys.stdout.write(output)\n",
    "    sys.stdout.flush()\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def LoadData(path, isTrain=False):\n",
    "    data = torchvision.datasets.ImageFolder(path)\n",
    "    if isTrain:\n",
    "        global n_classes\n",
    "        n_classes = len(data.classes)\n",
    "    \n",
    "    if isTrain:\n",
    "        prompt=\"Loading Training Data: \"\n",
    "    else:\n",
    "        prompt=\"Loading Testing Data: \"\n",
    "    n = 0.0\n",
    "    images = []\n",
    "    for img,label in data:\n",
    "        images.append(resize_image(img))\n",
    "        replace_cmd_line(prompt+str(round(n/len(data)*100)))\n",
    "        n+=1\n",
    "    print ''\n",
    "    images = np.array(images)\n",
    "    \n",
    "    labels = np.array([label for img,label in data.imgs])\n",
    "    labels = np.identity(len(data.classes))[labels]\n",
    "    \n",
    "    return DataSet(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data: 100.0\n",
      "Loading Testing Data: 99.0\n"
     ]
    }
   ],
   "source": [
    "trainset = LoadData(\"../data/faces_images/train/\", True)\n",
    "testset = LoadData(\"../data/faces_images/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1267, 128, 128, 3), (1267, 10), (96, 128, 128, 3), (96, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.images.shape, trainset.labels.shape, testset.images.shape, testset.labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 16384\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "steps = 1000\n",
    "\n",
    "n_input = height * width\n",
    "print n_classes,n_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial,name=\"weight\")\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial, name=\"bias\")\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,3,3,1], strides=[1,2,2,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.GeneratorContextManager at 0x7fa03359a950>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.as_default()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph Input\n",
    "x = tf.placeholder(tf.float32, [None, height,width,3], name=\"input_features\")\n",
    "y = tf.placeholder(tf.float32, [None, n_classes], name=\"labels\")\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "# layer 1 ?x128x128x3 => ?x64x64x64\n",
    "W_conv1 = weight_variable([3,3,3,64])\n",
    "b_conv1 = bias_variable([64])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1, name=\"h_conv1\")\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# layer 2 ?x64x64x64 => ?x32x32x128\n",
    "W_conv2 = weight_variable([3,3,64,128])\n",
    "b_conv2 = bias_variable([128])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, name=\"h_conv2\")\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# layer 3 ?x32x32x128 => ?x16x16x256\n",
    "W_conv3 = weight_variable([3,3,128,256])\n",
    "b_conv3 = bias_variable([256])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3, name=\"h_conv3\")\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "# layer 4 ?x16x16x256 => ?x8x8x512\n",
    "W_conv4 = weight_variable([3,3,256,512])\n",
    "b_conv4 = bias_variable([512])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_pool3, W_conv4) + b_conv4, name=\"h_conv4\")\n",
    "h_pool4 = max_pool_2x2(h_conv4)\n",
    "\n",
    "# fully connected layer 1  ?x8x8x512 => ?x1024\n",
    "W_fc1 = weight_variable([8*8*512,1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool4_flat = tf.reshape(h_pool4, [-1, 8*8*512], name=\"flattened_pool_layer\")\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool4_flat,W_fc1) + b_fc1, name=\"h_fc1\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob, name=\"h_fc1_drop\")\n",
    "\n",
    "# fully connected layer 2   ?x1024 => ?xn_classes\n",
    "W_fc2 = weight_variable([1024,n_classes])\n",
    "b_fc2 = bias_variable([n_classes])\n",
    "y_conv = tf.matmul(h_fc1_drop ,W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv), name=\"cross_entropy\")\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=0.01,name=\"optimizer\").minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y,1), name=\"correct_prediction\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32), name=\"accuracy\")\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter(\"log\", y_conv.graph);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, \"saved models/model\"+str(n_classes)+\".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0\n",
      "step 10, training accuracy 0\n",
      "step 20, training accuracy 1\n",
      "step 30, training accuracy 0\n",
      "Epochs Completed:  1\n",
      "step 40, training accuracy 0.15625\n",
      "step 50, training accuracy 0.28125\n",
      "step 60, training accuracy 0.15625\n",
      "step 70, training accuracy 0.15625\n",
      "Epochs Completed:  2\n",
      "step 80, training accuracy 0.09375\n",
      "step 90, training accuracy 0.28125\n",
      "step 100, training accuracy 0.3125\n"
     ]
    }
   ],
   "source": [
    "graphx = []\n",
    "graphy = []\n",
    "for i in range(steps+1):\n",
    "    batch = trainset.next_batch(batch_size)\n",
    "#     print i,\n",
    "    if i%10==0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0}, session=sess)\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "        graphx.append(i)\n",
    "        graphy.append(train_accuracy*100)\n",
    "    train_step.run(feed_dict={x: batch[0], y: batch[1], keep_prob:0.5}, session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print graphy\n",
    "plt.plot(graphx,graphy)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_accuracy = accuracy.eval(feed_dict={x: testset.images, y: testset.labels, keep_prob: 1.0}, session=sess)\n",
    "print 'test accuracy %g' % test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"saved models/model\"+str(n_classes)+\".ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
